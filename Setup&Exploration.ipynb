{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03825804-887f-44e6-8f49-a10671863a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da14fb1c-8190-4ffe-a876-cb6f22cd2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7b2dc-c423-433d-812e-7fabd00a9fb9",
   "metadata": {},
   "source": [
    "### Initiate SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "144c784b-934a-4cf8-96b1-f627626622f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/24 16:00:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"MySparkSession\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2992e-a92a-41b5-a4dc-28dbce1d178b",
   "metadata": {},
   "source": [
    "### Exlore Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16800239-592c-4b71-9c39-f79b51b24bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=MySparkSession>\n"
     ]
    }
   ],
   "source": [
    "spark_context = spark_session.sparkContext\n",
    "print(spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78296b6c-6948-4b63-bdd0-b24f3a2638d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n",
      "3.11\n",
      "local[*]\n",
      "None\n",
      "manulabricole\n",
      "MySparkSession\n",
      "local-1690207239678\n",
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(spark_context.version)\n",
    "print(spark_context.pythonVer)\n",
    "print(spark_context.master)\n",
    "print(str(spark_context.sparkHome))\n",
    "print(str(spark_context.sparkUser()))\n",
    "print(spark_context.appName)\n",
    "print(spark_context.applicationId)\n",
    "print(spark_context.defaultParallelism)\n",
    "print(spark_context.defaultMinPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "728d1e92-a3d0-4bdd-8686-1400ddfc42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Web UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Web UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc02a0-e73b-4350-a822-102e81386333",
   "metadata": {},
   "source": [
    "### Play with RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f26cd6-0415-4960-a618-4dc1bec9cd60",
   "metadata": {},
   "source": [
    "#### Create RDD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23e275fa-b716-422c-a658-d2032a591bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark_session.sparkContext.parallelize([(\"a\", 7), (\"a\", 2), (\"b\", 2)])\n",
    "rdd2 = spark_session.sparkContext.parallelize([(\"value4\", 2), (\"value5\", 1), (\"value6\", 1)])\n",
    "rdd3 = spark_session.sparkContext.parallelize(range(100))\n",
    "rdd4 = spark_session.sparkContext.parallelize([(\"key1\", [1, 2, 3]), (\"key2\", [4, 5])])\n",
    "rdd4 = spark_session.sparkContext.parallelize([(\"key1\", [1, 2, 3]), (\"key2\", [4, 5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4344490c-c621-4e13-bdb3-c25483ab4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', 7, 7, 'a'), ('a', 2, 2, 'a'), ('b', 2, 2, 'b')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.map(lambda x: x+(x[1],x[0])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "325881e5-1be0-40d5-9d22-5b92d0448d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['value4', 2, 2, 'value4', 'value5', 1, 1, 'value5', 'value6', 1, 1, 'value6']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5 = rdd2.flatMap(lambda x: x+(x[1],x[0]))\n",
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddacd65-1707-4be3-afbd-1f79fb7aa16c",
   "metadata": {},
   "source": [
    "#### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09fe6c-97f7-485b-90d5-567b8d80932c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a2862-a06b-43bf-bd14-8903785025e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99897485-eebe-4241-91e4-040ab6da5006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|  Python|        100|\n",
      "|    Java|        200|\n",
      "|   Scala|         50|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Python\", 100), (\"Java\", 200), (\"Scala\", 50)]\n",
    "columns = [\"language\", \"users_count\"]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(data)\n",
    "rows = rdd.map(lambda x: Row(language=x[0], users_count=int(x[1])))\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark_session.createDataFrame(rows)\n",
    "\n",
    "# Print DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a6cc881-6bb2-4463-bc87-bde54c19db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63f9f088-7527-4b32-a388-b7b171520b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'Python': 1, 'Java': 1, 'Scala': 1})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fde284-9812-4fa4-a7a2-ceff86766e57",
   "metadata": {},
   "source": [
    "### Decouverte des listes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8adfe6db-e7cf-4372-a9dd-fc65bb0e4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb1eb988-03be-467f-8df7-488e499ee881",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark_session.sparkContext.parallelize(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c44a6-23b1-432e-a611-fad0c2572499",
   "metadata": {},
   "source": [
    "#### Lazy Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f148675-0f5b-4ee3-b758-1154cbd89031",
   "metadata": {},
   "source": [
    "Lorsque vous effectuez des transformations sur un RDD ou un DataFrame dans Spark, ces transformations ne sont pas immédiatement appliquées aux données. À la place, Spark les conserve sous forme de \"plan d'exécution\" (logical execution plan), qui est essentiellement une série d'opérations à effectuer sur les données. Les plans d'exécution sont construits de manière à optimiser les opérations et à minimiser les mouvements de données sur le cluster.\n",
    "\n",
    "Ce n'est que lorsque vous appelez une \"action\" sur le RDD ou le DataFrame que les transformations sont réellement exécutées. Une action est une opération qui retourne un résultat concret (par exemple, count(), collect(), saveAsTextFile()). À ce moment-là, Spark déclenche le calcul des transformations en utilisant le plan d'exécution conservé, et les opérations sont effectuées de manière distribuée sur les nœuds du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6248fc5f-6f0d-4a4f-ab7e-ab3abb8646df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_rdd = rdd.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "929a7fbe-8dc3-4aae-be83-d4981960263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rdd = mapped_rdd.filter(lambda x: x % 4 == 0) # Not executed yet because not called. Just a execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02828493-c01b-4734-9f8f-73379a97d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rdd.collect() # Now spark will run the filter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85d134b8-0dd4-4d67-ae3b-9238f589f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = l*1000000\n",
    "rdd_ll = spark_session.sparkContext.parallelize(ll)\n",
    "mapped_rdd_ll = rdd_ll.map(lambda x: x * 2)\n",
    "filtered_rdd_ll = mapped_rdd_ll.filter(lambda x: x % 4 == 0) # Not executed yet because not called. Just a execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "238ecb4c-aec3-4348-b0a1-c7c39cea6db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 4, 8, 4, 8, 4, 8, 4, 8]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rdd_ll.collect()[:10] # Now spark will run the filter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11031073-bfc5-4515-930d-8df197da1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession when you're done\n",
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74c4f1-2751-4413-96cf-0b928bf0a094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121d3b6-c058-4355-bca6-62e05b9dd995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0453d-8e08-4cb5-8252-13c2e1a2b466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
