{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29511fb6-8298-4876-8d66-085922e1c149",
   "metadata": {},
   "source": [
    "# Import & Launch Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "933d36b3-ff00-4c15-a079-88445fb43f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "41157a86-0626-4cd1-b023-a05f6006b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b8059-849e-4970-bd56-57f06201ed47",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "dd524ce1-0332-4ac2-a11b-d24eea4dfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_context_infos(context):\n",
    "    print(\"VERSION: \",context.version)\n",
    "    print(\"PYTHON_VERSION: \", context.pythonVer)\n",
    "    print(\"MASTER: \", context.master)\n",
    "    print(\"SPARK_HOME: \", str(context.sparkHome))\n",
    "    print(\"SPARK_USER: \", str(context.sparkUser()))\n",
    "    print(\"APP_NAME: \", context.appName)\n",
    "    print(\"APP_ID: \", context.applicationId)\n",
    "    print(\"DEFAULT_PARALLESLISM: \", context.defaultParallelism)\n",
    "    print(\"DEFAULT_PARTITION: \", context.defaultMinPartitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed16276-8f60-459d-96e0-a2e30c3e612c",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1cb17d38-9eba-4792-bd91-5e524fa7a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manulabricole/Documents/CDN/BigData\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "412e4ff6-8253-4a37-8d69-1998a0600acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Web UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"book_session\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Web UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "27975928-0d57-4d22-9a1a-eb5f689ac7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION:  3.4.1\n",
      "PYTHON_VERSION:  3.11\n",
      "MASTER:  local[*]\n",
      "SPARK_HOME:  None\n",
      "SPARK_USER:  manulabricole\n",
      "APP_NAME:  book_session\n",
      "APP_ID:  local-1690356127101\n",
      "DEFAULT_PARALLESLISM:  10\n",
      "DEFAULT_PARTITION:  2\n"
     ]
    }
   ],
   "source": [
    "spark_context = spark_session.sparkContext\n",
    "print_context_infos(spark_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3b9e0-ce5d-4ab6-807f-6d6f524d62f1",
   "metadata": {},
   "source": [
    "## Import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "3afd264d-feaa-40aa-89e3-2f86cf92ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manulabricole/Documents/CDN/BigData/beautifull_story.txt\n"
     ]
    }
   ],
   "source": [
    "filename = \"beautifull_story.txt\"\n",
    "text_path = os.path.join(cwd, filename)\n",
    "print(text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e6c976ac-70bb-43ad-827e-6ea497bbc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = spark_session.sparkContext.textFile(text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "2b545a7e-d900-47e6-9d01-c2e837378830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg's Beautiful Stories from Shakespeare, by E. Nesbit\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n"
     ]
    }
   ],
   "source": [
    "for line in text_rdd.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7141302-80b2-4993-bb24-ac446e3b8d4f",
   "metadata": {},
   "source": [
    "# Explore the book shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7f3cc-273e-4551-a45e-74fff8cb0cd5",
   "metadata": {},
   "source": [
    "## Main infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7b79fdd1-46e6-4921-ad29-d99b71aea39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = text_rdd.count()\n",
    "words_rdd = text_rdd.flatMap(lambda line: line.split())\n",
    "num_words = words_rdd.count()\n",
    "num_distinct_words = words_rdd.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "59376135-2d46-4b37-929e-17fbb76fc218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lines           -->  7422\n",
      "Number of words           -->  52592\n",
      "Number of Different Words -->  10264\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Lines           --> \", num_lines)\n",
    "print(\"Number of words           --> \", num_words)\n",
    "print(\"Number of Different Words --> \", num_distinct_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f761e2e-32d4-4df7-a34e-6a78ebfab60b",
   "metadata": {},
   "source": [
    "## Theme aborded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49569df6-e56e-4e6b-ad93-a05a3725f192",
   "metadata": {},
   "source": [
    "### Top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "39eb4f13-dc99-4adc-8313-491bf978d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each word\n",
    "word_counts_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Sort the words based on their count in descending order\n",
    "sorted_word_counts_rdd = word_counts_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "69270dc0-233c-483d-96d2-4f1381b1b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 2072), ('and', 1774), ('to', 1451), ('.', 1373), ('of', 1152), ('a', 937), ('he', 805), ('was', 762), ('his', 687), ('in', 638)]\n"
     ]
    }
   ],
   "source": [
    "# Take the first ten words from the sorted list\n",
    "top_10_words = sorted_word_counts_rdd.take(10)\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4bb33-0cb2-4cbc-9b86-e40ff3ab0bd4",
   "metadata": {},
   "source": [
    "### Top 10 words filtered"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8269785-f6f9-45a4-9990-1a9e3511fcdd",
   "metadata": {},
   "source": [
    "We use the nltk library to prevent from catching useless words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6efc7d8c-8272-482b-90ae-2f3f5a4a941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f475c75c-0a6b-4b69-8b95-ccdd8352a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manulabricole/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/manulabricole/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/manulabricole/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize NLTK and download the averaged_perceptron_tagger data package\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fcf51e9d-f055-4f09-a0a3-bbc5737458f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pattern(word):\n",
    "    # Define a regular expression pattern to remove unwanted characters\n",
    "    pattern = r'[^A-Za-z0-9]'\n",
    "    \n",
    "    # Use re.sub to remove unwanted characters from the word\n",
    "    cleaned_word = re.sub(pattern, '', word)\n",
    "    \n",
    "    return cleaned_word\n",
    "\n",
    "# Function to check if a word is a verb using NLTK's part-of-speech tagging\n",
    "def is_verb(word):\n",
    "    tagged_word = pos_tag([word])\n",
    "    return tagged_word[0][1].startswith(\"VB\")\n",
    "\n",
    "# Function to filter out unwanted characters and check if a word is a verb\n",
    "def is_valid_word(word):\n",
    "    word = clean_pattern(word)\n",
    "    word = word.lower()\n",
    "    return word.isalpha() and word not in stop_words and not is_verb(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f79f8114-5e5d-48cb-9d3b-ce6b17ed931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1549:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We pass from 52592 to 20782 words ! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tokenize each line by splitting it into words, remove stop words and unwanted characters\n",
    "words_rdd = text_rdd.flatMap(lambda line: word_tokenize(line)).filter(is_valid_word)\n",
    "new_number = words_rdd.count()\n",
    "print(f\"We pass from {num_words} to {new_number} words ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "c836b268-8b91-4d1b-a165-346ace52aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each word. reduceByKLey receive a function. \n",
    "# For the same key, a and b are the values coming from two key value pair. We keep the common key but make the sum of the values\n",
    "word_counts_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Sort the words based on their count in descending order\n",
    "sorted_word_counts_rdd = word_counts_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f06d1108-a150-4969-803f-355d6194ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King: 183\n",
      "would: 174\n",
      "love: 146\n",
      "Duke: 124\n",
      "one: 111\n",
      "man: 110\n",
      "could: 106\n",
      "told: 103\n",
      "father: 88\n",
      "like: 85\n",
      "Project: 83\n",
      "wife: 82\n",
      "Claudio: 73\n",
      "thought: 71\n",
      "Timon: 70\n",
      "two: 68\n",
      "Othello: 68\n",
      "Macbeth: 66\n",
      "daughter: 65\n",
      "day: 64\n"
     ]
    }
   ],
   "source": [
    "for word, count in sorted_word_counts_rdd.take(20):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f07e1-a966-4eae-ae4e-613601c48ba9",
   "metadata": {},
   "source": [
    "## Découpe d'histoires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3881ded-6590-4f45-a417-7ce8ef6367eb",
   "metadata": {},
   "source": [
    "### Study and extract the chapters names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0d3e04b6-ba60-457d-8a61-9f0c298c3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(lines_rdd, start_keyword, end_keyword):\n",
    "    start_idx = lines_rdd.zipWithIndex().filter(lambda x: start_keyword in x[0]).map(lambda x: x[1]).first()\n",
    "    end_idx = lines_rdd.zipWithIndex().filter(lambda x: end_keyword in x[0]).map(lambda x: x[1]).first()\n",
    "    return start_idx, end_idx\n",
    "\n",
    "def extract_content_between_indices(lines_rdd, start_idx, end_idx):\n",
    "    return lines_rdd.zipWithIndex().filter(lambda x: start_idx < x[1] < end_idx).map(lambda x: x[0]).filter(lambda x: x.strip())\n",
    "\n",
    "def extract_chapter_names(lines):\n",
    "    chapter_names = []\n",
    "    for line in lines:\n",
    "        # Split the line by \" . . . . . . . . \"\n",
    "        parts = line.split(\" . . . . . . . . \")\n",
    "        # Take the first part and strip any leading/trailing whitespace\n",
    "        chapter_name = parts[0].strip()\n",
    "        if chapter_name:\n",
    "            chapter_names.append(chapter_name)\n",
    "    return chapter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b2c2eed6-c02e-4a33-ab9a-eb4341446cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx, end_idx = find_indices(lines_rdd, \"CONTENTS\", \"ILLUSTRATIONS\")\n",
    "chapter_content_rdd = extract_content_between_indices(lines_rdd, start_idx, end_idx)\n",
    "chapter_names = extract_chapter_names(chapter_content_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ad836f69-4329-4e33-b9e8-05937d6b9b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START  -->  240\n",
      "END    -->  271\n",
      "['PREFACE', 'A BRIEF LIFE OF SHAKESPEARE', \"A MIDSUMMER NIGHT'S DREAM\", 'THE TEMPEST', 'AS YOU LIKE IT', \"THE WINTER'S TALE\", 'KING LEAR', 'TWELFTH NIGHT', 'MUCH ADO ABOUT NOTHING', 'ROMEO AND JULIET', 'PERICLES', 'HAMLET', 'CYMBELINE', 'MACBETH', 'THE COMEDY OF ERRORS', 'THE MERCHANT OF VENICE', 'TIMON OF ATHENS', 'OTHELLO', 'THE TAMING OF THE SHREW', 'MEASURE FOR MEASURE', 'TWO GENTLEMEN OF VERONA', \"ALL'S WELL THAT ENDS WELL\", 'PRONOUNCING VOCABULARY OF NAMES', 'QUOTATIONS FROM SHAKESPEARE']\n"
     ]
    }
   ],
   "source": [
    "print(\"START  --> \", start_idx)\n",
    "print(\"END    --> \", end_idx)\n",
    "\n",
    "if \"PAGE\" in chapter_names:\n",
    "    chapter_names.remove(\"PAGE\")\n",
    "print(chapter_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc48f7-9378-4a96-b35c-9e03df5ce24c",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6ed93fe7-6edc-434c-9ca4-3a728f332dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(sentence):\n",
    "    # Replace spaces with underscores\n",
    "    sentence = sentence.replace(\" \", \"_\")\n",
    "\n",
    "    # Remove special characters using regex\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "42400d7d-16c3-463d-af39-21af8e9e47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_index_rdd = lines_rdd.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "fa1df6bb-ae5e-49a8-9ea3-a01a466b1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_lines_rdd = lines_with_index_rdd.filter(lambda x: x[1] > 365)\n",
    "max_index = filtered_lines_rdd.map(lambda x: x[1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "7530ccdb-2fa7-4900-9b2e-98679676a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370, 595, 793, 959, 1179, 1304, 1543, 1964, 2213, 2399, 2623, 2856, 3123, 3398, 3585, 3932, 4230, 4499, 4785, 5137, 5407, 5584, 7421]\n"
     ]
    }
   ],
   "source": [
    "chapter_indices_rdd = filtered_lines_rdd.filter(lambda x: any(name in x[0] for name in chapter_names)).map(lambda x: x[1])\n",
    "chapter_indices_list = chapter_indices_rdd.collect()\n",
    "chapter_indices_list.append(max_index)\n",
    "print(chapter_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "77549eac-985c-4244-9957-23e7525e9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapters 1 - A_MIDSUMMER_NIGHTS_DREAM\n",
      "Chapters 2 - THE_TEMPEST\n",
      "Chapters 3 - AS_YOU_LIKE_IT\n",
      "Chapters 4 - THE_WINTERS_TALE\n",
      "Chapters 5 - KING_LEAR\n",
      "Chapters 6 - TWELFTH_NIGHT\n",
      "Chapters 7 - MUCH_ADO_ABOUT_NOTHING\n",
      "Chapters 8 - ROMEO_AND_JULIET\n",
      "Chapters 9 - PERICLES\n",
      "Chapters 10 - HAMLET\n",
      "Chapters 11 - CYMBELINE\n",
      "Chapters 12 - MACBETH\n",
      "Chapters 13 - THE_COMEDY_OF_ERRORS\n",
      "Chapters 14 - THE_MERCHANT_OF_VENICE\n",
      "Chapters 15 - TIMON_OF_ATHENS\n",
      "Chapters 16 - OTHELLO\n",
      "Chapters 17 - THE_TAMING_OF_THE_SHREW\n",
      "Chapters 18 - MEASURE_FOR_MEASURE\n",
      "Chapters 19 - TWO_GENTLEMEN_OF_VERONA\n",
      "Chapters 20 - ALLS_WELL_THAT_ENDS_WELL\n",
      "Chapters 21 - PRONOUNCING_VOCABULARY_OF_NAMES\n",
      "Chapters 22 - QUOTATIONS_FROM_SHAKESPEARE\n"
     ]
    }
   ],
   "source": [
    "for _, index in enumerate(chapter_indices_list[:-1]):\n",
    "    name = clean_title(filtered_lines_rdd.filter(lambda l: l[1] == index).collect()[0][0])\n",
    "    print(f\"Chapters {_+1} - {name}\")\n",
    "\n",
    "    start_index = chapter_indices_list[_]\n",
    "    end_index =chapter_indices_list[_+1]\n",
    "  \n",
    "    content_rdd = filtered_lines_rdd.filter(lambda chapter: end_index-1 >= chapter[1] >= start_index)\n",
    "    # Save the chapter text to a separate text file, or perform other operations as needed\n",
    "    content_rdd.saveAsTextFile(f'stories/chapter_{_+1}_{name}.txt')\n",
    "    # indexed_rdd.filter(lambda x: start_index <= x[1] <= end_index).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a2c5d-fcd2-4a20-af41-b4f1dc920333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
