{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03825804-887f-44e6-8f49-a10671863a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da14fb1c-8190-4ffe-a876-cb6f22cd2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "144c784b-934a-4cf8-96b1-f627626622f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/24 12:00:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession with the appropriate configuration\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"MySparkSession\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16800239-592c-4b71-9c39-f79b51b24bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=MySparkSession>\n"
     ]
    }
   ],
   "source": [
    "spark_context = spark_session.sparkContext\n",
    "print(spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "944fa947-e32b-4475-b00c-a035c92c3635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|  Python|        100|\n",
      "|    Java|        200|\n",
      "|   Scala|         50|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [(\"Python\", 100), (\"Java\", 200), (\"Scala\", 50)]\n",
    "\n",
    "# Define columns\n",
    "columns = [\"language\", \"users_count\"]\n",
    "\n",
    "# Create RDD of Row objects\n",
    "rdd = spark_session.sparkContext.parallelize(data)\n",
    "rows = rdd.map(lambda x: Row(language=x[0], users_count=int(x[1])))\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark_session.createDataFrame(rows)\n",
    "\n",
    "# Print DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "728d1e92-a3d0-4bdd-8686-1400ddfc42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Web UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Web UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11031073-bfc5-4515-930d-8df197da1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stop the SparkSession when you're done\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
