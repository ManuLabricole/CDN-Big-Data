{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03825804-887f-44e6-8f49-a10671863a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da14fb1c-8190-4ffe-a876-cb6f22cd2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7b2dc-c423-433d-812e-7fabd00a9fb9",
   "metadata": {},
   "source": [
    "### Initiate SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "144c784b-934a-4cf8-96b1-f627626622f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession with the appropriate configuration\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"MySparkSession\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2992e-a92a-41b5-a4dc-28dbce1d178b",
   "metadata": {},
   "source": [
    "### Exlore Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16800239-592c-4b71-9c39-f79b51b24bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=MySparkSession>\n"
     ]
    }
   ],
   "source": [
    "spark_context = spark_session.sparkContext\n",
    "print(spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78296b6c-6948-4b63-bdd0-b24f3a2638d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n",
      "3.11\n",
      "local[*]\n",
      "None\n",
      "manulabricole\n",
      "MySparkSession\n",
      "local-1690194998587\n",
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(spark_context.version)\n",
    "print(spark_context.pythonVer)\n",
    "print(spark_context.master)\n",
    "print(str(spark_context.sparkHome))\n",
    "print(str(spark_context.sparkUser()))\n",
    "print(spark_context.appName)\n",
    "print(spark_context.applicationId)\n",
    "print(spark_context.defaultParallelism)\n",
    "print(spark_context.defaultMinPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "728d1e92-a3d0-4bdd-8686-1400ddfc42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Web UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Web UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc02a0-e73b-4350-a822-102e81386333",
   "metadata": {},
   "source": [
    "### Play with RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f26cd6-0415-4960-a618-4dc1bec9cd60",
   "metadata": {},
   "source": [
    "#### Create RDD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23e275fa-b716-422c-a658-d2032a591bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark_session.sparkContext.parallelize([(\"value1\", 7), (\"value2\", 2), (\"value3\", 2)])\n",
    "rdd2 = spark_session.sparkContext.parallelize([(\"value4\", 2), (\"value5\", 1), (\"value6\", 1)])\n",
    "rdd3 = spark_session.sparkContext.parallelize(range(100))\n",
    "rdd4 = spark_session.sparkContext.parallelize([(\"key1\", [1, 2, 3]), (\"key2\", [4, 5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddacd65-1707-4be3-afbd-1f79fb7aa16c",
   "metadata": {},
   "source": [
    "#### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99897485-eebe-4241-91e4-040ab6da5006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|  Python|        100|\n",
      "|    Java|        200|\n",
      "|   Scala|         50|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Python\", 100), (\"Java\", 200), (\"Scala\", 50)]\n",
    "columns = [\"language\", \"users_count\"]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(data)\n",
    "rows = rdd.map(lambda x: Row(language=x[0], users_count=int(x[1])))\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark_session.createDataFrame(rows)\n",
    "\n",
    "# Print DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a6cc881-6bb2-4463-bc87-bde54c19db93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[15] at readRDDFromFile at PythonRDD.scala:287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(rdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f088-7527-4b32-a388-b7b171520b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11031073-bfc5-4515-930d-8df197da1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stop the SparkSession when you're done\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74c4f1-2751-4413-96cf-0b928bf0a094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
